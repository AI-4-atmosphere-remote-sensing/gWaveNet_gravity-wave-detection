Note: We used a custom ViT model as the base model did not learnt anythnig. Following are the differences. Details are in /all source code/vit_no_custom_kernel_layer.py


the base model
	patch_size=16, 
	num_heads=12,
	num_layers=12,
	image_size=224,
	mlp_dim=3072,

the custom model:
	num_classes = 2
	patch_size = 40
	num_heads=6 # Number of attention heads
	num_layer=6 #Number of attention layer
	image_size=200
	mlp_dim=1024
	att_size=32
	batch_size=128
	epochs=2000
